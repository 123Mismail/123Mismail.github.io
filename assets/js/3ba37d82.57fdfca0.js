"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[979],{2575(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"c8-advanced-simulation","title":"Chapter 8: Advanced Simulation Techniques","description":"Learning Outcomes","source":"@site/chapters/c8-advanced-simulation.md","sourceDirName":".","slug":"/c8-advanced-simulation","permalink":"/chapters/c8-advanced-simulation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"c8-advanced-simulation","title":"Chapter 8: Advanced Simulation Techniques","sidebar_label":"C8: Advanced Simulation","sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"C7: Unity Simulation","permalink":"/chapters/c7-unity-simulation"},"next":{"title":"C9: Real-Time Control","permalink":"/chapters/c9-real-time-control"}}');var i=t(4848),r=t(8453);const a={id:"c8-advanced-simulation",title:"Chapter 8: Advanced Simulation Techniques",sidebar_label:"C8: Advanced Simulation",sidebar_position:8},s="Chapter 8: Advanced Simulation Techniques",l={},d=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Overview",id:"overview",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Domain Randomization for Robust Policy Learning",id:"domain-randomization-for-robust-policy-learning",level:2},{value:"Systematic Parameter Randomization",id:"systematic-parameter-randomization",level:3},{value:"Physics Parameter Randomization",id:"physics-parameter-randomization",level:3},{value:"Multi-Robot Coordination in Simulation",id:"multi-robot-coordination-in-simulation",level:2},{value:"Coordination Framework",id:"coordination-framework",level:3},{value:"Sim-to-Real Transfer Framework",id:"sim-to-real-transfer-framework",level:2},{value:"Policy Deployment System",id:"policy-deployment-system",level:3},{value:"Python Interface for Sim-to-Real Transfer",id:"python-interface-for-sim-to-real-transfer",level:3},{value:"Summary",id:"summary",level:2},{value:"Review Questions",id:"review-questions",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"chapter-8-advanced-simulation-techniques",children:"Chapter 8: Advanced Simulation Techniques"})}),"\n",(0,i.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Implement"})," domain randomization techniques to improve sim-to-real transfer performance"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Design"})," multi-robot coordination systems in simulation environments"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Deploy"})," reinforcement learning policies from simulation to real hardware platforms"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Evaluate"})," simulation fidelity and transferability metrics for humanoid robotics applications"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(e.p,{children:"Chapters 5-7 introduced foundational simulation environments: Gazebo for physics-based simulation, NVIDIA Isaac Sim for GPU-accelerated photorealistic rendering, and Unity for real-time visualization and rapid prototyping. While these platforms provide essential capabilities for humanoid robotics development, advanced applications require sophisticated techniques to bridge the reality gap between simulation and hardware deployment."}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Advanced simulation techniques"})," encompass methods that enhance simulation fidelity, enable transfer of learned behaviors to real robots, and support complex multi-agent scenarios. These include ",(0,i.jsx)(e.strong,{children:"domain randomization"})," for robust policy learning, ",(0,i.jsx)(e.strong,{children:"multi-robot coordination"})," frameworks for swarm robotics, and ",(0,i.jsx)(e.strong,{children:"sim-to-real transfer"})," methodologies that account for modeling inaccuracies and environmental differences."]}),"\n",(0,i.jsx)(e.p,{children:"This chapter explores these advanced techniques, focusing on practical implementation strategies for humanoid robotics. You will learn to configure domain randomization for robust controller training, implement multi-robot coordination algorithms, and deploy reinforcement learning policies from simulation to real hardware using frameworks like RL-SAR (Reinforcement Learning Simulation to ARgumentation)."}),"\n",(0,i.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Domain Randomization"}),": Technique that randomizes simulation parameters (masses, friction, lighting, textures) during training to improve policy robustness to real-world variations"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sim-to-Real Transfer"}),': Process of deploying policies trained in simulation to real hardware, addressing the "reality gap" between simulated and physical environments']}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-Robot Coordination"}),": Frameworks and algorithms for coordinating multiple robots simultaneously in shared environments"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"System Identification"}),": Process of determining accurate physical parameters (masses, inertias, friction coefficients) of real robots for simulation model refinement"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Policy Conversion"}),": Techniques for converting reinforcement learning policies between different frameworks and hardware platforms (PyTorch to ONNX, etc.)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Observation Buffer"}),": Mechanism for maintaining temporal history of sensor observations for policy input in dynamic control tasks"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Reality Gap"}),": Discrepancy between simulation and real-world robot behavior due to modeling inaccuracies and environmental differences"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Systematic Parameter Randomization"}),": Methodical approach to varying simulation parameters within realistic bounds to improve policy generalization"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"domain-randomization-for-robust-policy-learning",children:"Domain Randomization for Robust Policy Learning"}),"\n",(0,i.jsx)(e.p,{children:"Domain randomization addresses the reality gap by training policies across diverse simulation conditions, improving their robustness to real-world variations:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Randomization  \u2502\u2500\u2500\u2500\u25ba\u2502  Simulation      \u2502\u2500\u2500\u2500\u25ba\u2502  Policy Training \u2502\n\u2502  Parameters     \u2502    \u2502  Environment     \u2502    \u2502  Loop           \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502                  \u2502\n\u2502  - Masses       \u2502    \u2502  - Physics       \u2502    \u2502  - Collect       \u2502\n\u2502  - Friction     \u2502    \u2502  - Rendering     \u2502    \u2502    trajectories  \u2502\n\u2502  - Lighting     \u2502    \u2502  - Sensors       \u2502    \u2502  - Update        \u2502\n\u2502  - Textures     \u2502    \u2502                  \u2502    \u2502    policy        \u2502\n\u2502  - Dynamics     \u2502    \u2502                  \u2502    \u2502                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Policy         \u2502\n\u2502  Generalization \u2502\n\u2502  (Robust to     \u2502\n\u2502   Real-World    \u2502\n\u2502   Variations)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(e.h3,{id:"systematic-parameter-randomization",children:"Systematic Parameter Randomization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# domain_randomization.py - Systematic parameter randomization for humanoid simulation\nimport numpy as np\nimport random\nfrom typing import Dict, Tuple, Any\n\nclass DomainRandomizer:\n    def __init__(self):\n        # Define randomization ranges for key parameters\n        self.randomization_ranges = {\n            # Robot dynamics parameters\n            \'robot_mass\': (0.8, 1.2),  # \xb120% mass variation\n            \'friction_coefficient\': (0.5, 1.5),  # Variable friction\n            \'joint_damping\': (0.5, 2.0),  # Joint damping variation\n            \'actuator_delay\': (0.0, 0.02),  # 0-20ms actuator delay\n\n            # Environmental parameters\n            \'gravity\': (9.61, 10.01),  # \xb10.2 m/s\xb2 gravity variation\n            \'ground_friction\': (0.7, 1.3),  # Ground friction variation\n\n            # Sensor noise parameters\n            \'imu_noise\': (0.001, 0.01),  # IMU noise variation\n            \'encoder_noise\': (0.0001, 0.001),  # Encoder noise variation\n        }\n\n        # Store current randomization values\n        self.current_params = {}\n        self.reset_randomization()\n\n    def reset_randomization(self):\n        """Reset all parameters to new random values within ranges"""\n        for param, (min_val, max_val) in self.randomization_ranges.items():\n            self.current_params[param] = random.uniform(min_val, max_val)\n        return self.current_params\n\n    def get_randomized_value(self, param_name: str, nominal_value: float) -> float:\n        """Get randomized value for a specific parameter"""\n        if param_name in self.current_params:\n            return nominal_value * self.current_params[param_name]\n        else:\n            return nominal_value\n\n    def randomize_robot_dynamics(self, robot_model):\n        """Apply randomization to robot dynamics properties"""\n        # Randomize link masses\n        for link in robot_model.links:\n            randomized_mass = self.get_randomized_value(\n                \'robot_mass\', link.mass\n            )\n            link.mass = randomized_mass\n\n            # Randomize friction coefficients\n            randomized_friction = self.get_randomized_value(\n                \'friction_coefficient\', link.friction_coeff\n            )\n            link.friction_coeff = randomized_friction\n\n            # Randomize joint damping\n            for joint in link.joints:\n                randomized_damping = self.get_randomized_value(\n                    \'joint_damping\', joint.damping\n                )\n                joint.damping = randomized_damping\n\n    def randomize_environment(self, simulation_env):\n        """Apply randomization to environmental parameters"""\n        # Randomize gravity\n        randomized_gravity = self.get_randomized_value(\n            \'gravity\', simulation_env.gravity\n        )\n        simulation_env.gravity = randomized_gravity\n\n        # Randomize ground properties\n        randomized_ground_friction = self.get_randomized_value(\n            \'ground_friction\', simulation_env.ground_friction\n        )\n        simulation_env.ground_friction = randomized_ground_friction\n\n        # Randomize lighting conditions (for vision-based tasks)\n        if hasattr(simulation_env, \'lighting\'):\n            simulation_env.lighting.intensity *= random.uniform(0.7, 1.3)\n            simulation_env.lighting.ambient_color = np.random.uniform(0.1, 1.0, 3)\n\n    def randomize_sensors(self, robot_sensors):\n        """Apply randomization to sensor properties"""\n        for sensor in robot_sensors:\n            if sensor.type == \'IMU\':\n                # Add noise to IMU readings\n                sensor.noise_level = self.get_randomized_value(\n                    \'imu_noise\', sensor.nominal_noise\n                )\n            elif sensor.type == \'ENCODER\':\n                # Add noise to encoder readings\n                sensor.noise_level = self.get_randomized_value(\n                    \'encoder_noise\', sensor.nominal_noise\n                )\n\nclass DomainRandomizationEnv:\n    """Environment wrapper that applies domain randomization"""\n\n    def __init__(self, base_env, randomization_freq=1000):\n        self.base_env = base_env\n        self.randomizer = DomainRandomizer()\n        self.randomization_freq = randomization_freq  # Randomize every N episodes\n        self.episode_count = 0\n\n    def reset(self):\n        """Reset environment with new randomization parameters"""\n        if self.episode_count % self.randomization_freq == 0:\n            # Apply new randomization parameters\n            self.randomizer.reset_randomization()\n            self.randomizer.randomize_robot_dynamics(self.base_env.robot_model)\n            self.randomizer.randomize_environment(self.base_env.simulation)\n            self.randomizer.randomize_sensors(self.base_env.sensors)\n\n        self.episode_count += 1\n        return self.base_env.reset()\n\n    def step(self, action):\n        """Execute step in randomized environment"""\n        return self.base_env.step(action)\n\n    def get_randomization_stats(self):\n        """Get current randomization parameter values"""\n        return self.randomizer.current_params\n'})}),"\n",(0,i.jsx)(e.h3,{id:"physics-parameter-randomization",children:"Physics Parameter Randomization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# physics_randomization.py - Advanced physics parameter randomization\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\nclass PhysicsRandomizer:\n    """Advanced randomization of physics parameters for humanoid simulation"""\n\n    def __init__(self, robot_model, simulation_params):\n        self.robot_model = robot_model\n        self.sim_params = simulation_params\n        self.param_history = []  # Track parameter variations over time\n\n    def randomize_inertial_properties(self):\n        """Randomize inertial properties of robot links"""\n        for link in self.robot_model.links:\n            # Randomize mass (\xb120%)\n            mass_variation = np.random.uniform(0.8, 1.2)\n            link.mass = link.nominal_mass * mass_variation\n\n            # Randomize center of mass offset\n            com_offset = np.random.normal(0, 0.01, 3)  # \xb11cm offset\n            link.center_of_mass += com_offset\n\n            # Randomize inertia tensor with physical constraints\n            # Ensure the inertia tensor remains positive definite\n            inertia_perturbation = np.random.uniform(0.9, 1.1, 3)\n            link.inertia_tensor = np.diag(inertia_perturbation * np.diag(link.nominal_inertia_tensor))\n\n            # Apply random rotation to inertia tensor\n            random_rotation = R.random().as_matrix()\n            link.inertia_tensor = random_rotation @ link.inertia_tensor @ random_rotation.T\n\n    def randomize_contact_properties(self):\n        """Randomize contact and friction properties"""\n        for link in self.robot_model.links:\n            # Randomize static friction (Coulomb friction model)\n            static_friction = np.random.uniform(0.4, 1.2)\n            link.contact_properties.static_friction = static_friction\n\n            # Randomize dynamic friction\n            dynamic_friction = np.random.uniform(0.3, static_friction)\n            link.contact_properties.dynamic_friction = dynamic_friction\n\n            # Randomize restitution (bounciness)\n            restitution = np.random.uniform(0.0, 0.1)\n            link.contact_properties.restitution = restitution\n\n            # Randomize stiffness and damping for contact models\n            contact_stiffness = np.random.uniform(1000, 5000)  # N/m\n            contact_damping = np.random.uniform(50, 200)      # Ns/m\n            link.contact_properties.stiffness = contact_stiffness\n            link.contact_properties.damping = contact_damping\n\n    def randomize_actuator_dynamics(self):\n        """Randomize actuator dynamics and response characteristics"""\n        for joint in self.robot_model.joints:\n            # Randomize motor torque limits\n            torque_limit_factor = np.random.uniform(0.8, 1.2)\n            joint.torque_limit = joint.nominal_torque_limit * torque_limit_factor\n\n            # Randomize motor dynamics (first-order model)\n            time_constant = np.random.uniform(0.005, 0.020)  # 5-20ms response time\n            joint.motor_time_constant = time_constant\n\n            # Randomize gear ratio (for variable transmissions)\n            gear_ratio_factor = np.random.uniform(0.95, 1.05)  # \xb15% variation\n            joint.gear_ratio = joint.nominal_gear_ratio * gear_ratio_factor\n\n            # Randomize motor efficiency\n            efficiency = np.random.uniform(0.7, 0.95)  # 70-95% efficiency\n            joint.motor_efficiency = efficiency\n\n    def randomize_sensor_dynamics(self):\n        """Randomize sensor dynamics and noise characteristics"""\n        for sensor in self.robot_model.sensors:\n            if sensor.type == \'IMU\':\n                # Randomize IMU noise parameters\n                sensor.accelerometer_noise_density = np.random.uniform(1e-4, 5e-4)\n                sensor.gyroscope_noise_density = np.random.uniform(1e-5, 5e-5)\n                sensor.accelerometer_random_walk = np.random.uniform(1e-6, 5e-6)\n                sensor.gyroscope_random_walk = np.random.uniform(1e-7, 5e-7)\n\n                # Randomize bias parameters\n                sensor.accelerometer_bias = np.random.normal(0, 1e-3, 3)\n                sensor.gyroscope_bias = np.random.normal(0, 1e-4, 3)\n\n            elif sensor.type == \'ENCODER\':\n                # Randomize encoder resolution and noise\n                resolution_factor = np.random.uniform(0.9, 1.1)\n                sensor.resolution = int(sensor.nominal_resolution * resolution_factor)\n\n                noise_factor = np.random.uniform(0.5, 2.0)\n                sensor.noise_level = sensor.nominal_noise * noise_factor\n\n            elif sensor.type == \'FORCE_TORQUE\':\n                # Randomize force/torque sensor characteristics\n                sensor.force_noise = np.random.uniform(0.1, 1.0)  # N\n                sensor.torque_noise = np.random.uniform(0.01, 0.1)  # Nm\n                sensor.bias_drift = np.random.normal(0, 0.05, 6)  # N, Nm\n\n    def randomize_environmental_effects(self):\n        """Randomize environmental effects like air resistance, etc."""\n        # Randomize air density (affects drag)\n        air_density = np.random.uniform(1.1, 1.3)  # kg/m\xb3\n        self.sim_params.air_density = air_density\n\n        # Randomize wind effects\n        wind_velocity = np.random.normal(0, 0.5, 3)  # m/s\n        self.sim_params.wind_velocity = wind_velocity\n        self.sim_params.wind_gustiness = np.random.uniform(0.0, 0.5)\n\n        # Randomize temperature effects on materials\n        temperature = np.random.uniform(15, 35)  # Celsius\n        self.sim_params.temperature = temperature\n        # Temperature affects material properties, friction, etc.\n\n    def apply_randomization(self):\n        """Apply all randomization effects to the simulation"""\n        self.randomize_inertial_properties()\n        self.randomize_contact_properties()\n        self.randomize_actuator_dynamics()\n        self.randomize_sensor_dynamics()\n        self.randomize_environmental_effects()\n\n        # Store current parameters for analysis\n        current_params = {\n            \'timestamp\': self.sim_params.current_time,\n            \'mass_variation\': [link.mass/link.nominal_mass for link in self.robot_model.links],\n            \'friction_variation\': [link.contact_properties.static_friction for link in self.robot_model.links],\n            \'torque_limit_variation\': [joint.torque_limit/joint.nominal_torque_limit for joint in self.robot_model.joints]\n        }\n        self.param_history.append(current_params)\n\n        return current_params\n'})}),"\n",(0,i.jsx)(e.h2,{id:"multi-robot-coordination-in-simulation",children:"Multi-Robot Coordination in Simulation"}),"\n",(0,i.jsx)(e.p,{children:"Multi-robot coordination enables complex behaviors through distributed control and communication:"}),"\n",(0,i.jsx)(e.h3,{id:"coordination-framework",children:"Coordination Framework"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# multi_robot_coordination.py - Multi-robot coordination framework\nimport numpy as np\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple\nimport asyncio\n\nclass CoordinationStrategy(Enum):\n    CENTRALIZED = "centralized"\n    DECENTRALIZED = "decentralized"\n    HIERARCHICAL = "hierarchical"\n    MARKET_BASED = "market_based"\n\n@dataclass\nclass RobotState:\n    """State information for a single robot"""\n    robot_id: int\n    position: np.ndarray  # 3D position [x, y, z]\n    orientation: np.ndarray  # Quaternion [w, x, y, z]\n    velocity: np.ndarray  # 3D velocity [vx, vy, vz]\n    joint_angles: np.ndarray\n    joint_velocities: np.ndarray\n    battery_level: float\n    communication_range: float\n\n@dataclass\nclass Task:\n    """Task definition for multi-robot coordination"""\n    task_id: str\n    task_type: str  # \'navigation\', \'manipulation\', \'formation\', etc.\n    target_position: np.ndarray\n    priority: int\n    required_robots: int\n    estimated_completion_time: float\n    dependencies: List[str]  # Task IDs that must complete first\n\nclass CommunicationNetwork:\n    """Communication network for multi-robot systems"""\n\n    def __init__(self, max_range: float = 10.0):\n        self.max_range = max_range\n        self.robot_states: Dict[int, RobotState] = {}\n        self.topology = {}  # Adjacency list for communication graph\n\n    def add_robot(self, robot_state: RobotState):\n        """Add a robot to the communication network"""\n        self.robot_states[robot_state.robot_id] = robot_state\n        self.topology[robot_state.robot_id] = []\n\n    def update_robot_state(self, robot_id: int, new_state: RobotState):\n        """Update state of a specific robot"""\n        if robot_id in self.robot_states:\n            self.robot_states[robot_id] = new_state\n            self._update_topology()\n\n    def _update_topology(self):\n        """Update communication topology based on robot positions"""\n        for robot_id in self.robot_states:\n            neighbors = []\n            robot_pos = self.robot_states[robot_id].position\n\n            for other_id, other_state in self.robot_states.items():\n                if robot_id != other_id:\n                    distance = np.linalg.norm(robot_pos - other_state.position)\n                    if distance <= self.max_range:\n                        neighbors.append(other_id)\n\n            self.topology[robot_id] = neighbors\n\n    def broadcast_message(self, sender_id: int, message: dict):\n        """Broadcast message to all connected robots"""\n        if sender_id not in self.topology:\n            return []\n\n        recipients = self.topology[sender_id]\n        received_by = []\n\n        for recipient_id in recipients:\n            # Simulate message delivery with potential delays\n            delivery_delay = np.random.uniform(0.01, 0.1)  # 10-100ms delay\n            # In real implementation, this would send the message via ROS topics\n            received_by.append(recipient_id)\n\n        return received_by\n\n    def get_neighbors(self, robot_id: int) -> List[int]:\n        """Get list of communication neighbors for a robot"""\n        return self.topology.get(robot_id, [])\n\nclass MultiRobotCoordinator:\n    """Main coordinator for multi-robot systems"""\n\n    def __init__(self, strategy: CoordinationStrategy):\n        self.strategy = strategy\n        self.comm_network = CommunicationNetwork()\n        self.tasks: Dict[str, Task] = {}\n        self.robot_assignments: Dict[str, List[int]] = {}  # task_id -> list of robot_ids\n        self.task_queue = []\n\n    def add_robot(self, robot_state: RobotState):\n        """Add robot to the coordination system"""\n        self.comm_network.add_robot(robot_state)\n\n    def assign_task(self, task: Task, robot_ids: List[int]):\n        """Assign a task to specific robots"""\n        self.tasks[task.task_id] = task\n        self.robot_assignments[task.task_id] = robot_ids\n\n        # Create task assignment messages based on strategy\n        if self.strategy == CoordinationStrategy.DECENTRALIZED:\n            self._decentralized_assignment(task, robot_ids)\n        elif self.strategy == CoordinationStrategy.CENTRALIZED:\n            self._centralized_assignment(task, robot_ids)\n        elif self.strategy == CoordinationStrategy.HIERARCHICAL:\n            self._hierarchical_assignment(task, robot_ids)\n        elif self.strategy == CoordinationStrategy.MARKET_BASED:\n            self._market_based_assignment(task, robot_ids)\n\n    def _decentralized_assignment(self, task: Task, robot_ids: List[int]):\n        """Decentralized task assignment using consensus"""\n        # Each robot makes local decisions based on local information\n        for robot_id in robot_ids:\n            # Robot evaluates if it should take the task based on its state\n            robot_state = self.comm_network.robot_states[robot_id]\n\n            # Simple evaluation: distance to target, battery level, current load\n            distance_to_target = np.linalg.norm(\n                robot_state.position - task.target_position\n            )\n            fitness_score = (1.0 / (distance_to_target + 1)) * robot_state.battery_level\n\n            # Broadcast fitness score to neighbors\n            message = {\n                \'type\': \'fitness_score\',\n                \'task_id\': task.task_id,\n                \'robot_id\': robot_id,\n                \'fitness\': fitness_score,\n                \'timestamp\': self._get_timestamp()\n            }\n            self.comm_network.broadcast_message(robot_id, message)\n\n    def _centralized_assignment(self, task: Task, robot_ids: List[int]):\n        """Centralized task assignment with central controller"""\n        # Central controller has global knowledge and makes assignment decisions\n        central_controller = CentralizedController(self.comm_network)\n        assignment = central_controller.compute_optimal_assignment(task, robot_ids)\n\n        # Send assignment commands to robots\n        for robot_id in robot_ids:\n            command = {\n                \'type\': \'task_assignment\',\n                \'task_id\': task.task_id,\n                \'robot_id\': robot_id,\n                \'assignment\': assignment.get(robot_id, {}),\n                \'timestamp\': self._get_timestamp()\n            }\n            # Send command to robot (in real system, this would be a ROS service call)\n\n    def _hierarchical_assignment(self, task: Task, robot_ids: List[int]):\n        """Hierarchical task assignment with team leaders"""\n        # Organize robots into teams with leaders\n        teams = self._organize_teams(robot_ids)\n\n        for team_id, team_members in teams.items():\n            leader_id = team_members[0]  # First robot is leader\n            followers = team_members[1:]\n\n            # Leader coordinates task within team\n            leader_command = {\n                \'type\': \'team_coordination\',\n                \'task_id\': task.task_id,\n                \'team_id\': team_id,\n                \'leader_id\': leader_id,\n                \'followers\': followers,\n                \'target_position\': task.target_position,\n                \'timestamp\': self._get_timestamp()\n            }\n            self.comm_network.broadcast_message(leader_id, leader_command)\n\n    def _market_based_assignment(self, task: Task, robot_ids: List[int]):\n        """Market-based task assignment using auction/bidding"""\n        # Robots bid for tasks based on their capabilities and current state\n        bids = {}\n\n        for robot_id in robot_ids:\n            robot_state = self.comm_network.robot_states[robot_id]\n\n            # Calculate bid value based on robot capabilities\n            bid_value = self._calculate_robot_bid(robot_state, task)\n            bids[robot_id] = bid_value\n\n            # Broadcast bid to other robots\n            bid_message = {\n                \'type\': \'task_bid\',\n                \'task_id\': task.task_id,\n                \'robot_id\': robot_id,\n                \'bid_value\': bid_value,\n                \'timestamp\': self._get_timestamp()\n            }\n            self.comm_network.broadcast_message(robot_id, bid_message)\n\n        # Determine winner based on bids (simple highest bidder wins)\n        winner_id = max(bids, key=bids.get)\n        winner_command = {\n            \'type\': \'task_award\',\n            \'task_id\': task.task_id,\n            \'winner_id\': winner_id,\n            \'bid_value\': bids[winner_id],\n            \'timestamp\': self._get_timestamp()\n        }\n        # Broadcast award to all robots\n        for robot_id in robot_ids:\n            self.comm_network.broadcast_message(robot_id, winner_command)\n\n    def _organize_teams(self, robot_ids: List[int]) -> Dict[int, List[int]]:\n        """Organize robots into teams for hierarchical coordination"""\n        teams = {}\n        team_size = 3  # Each team has 3 robots\n\n        for i, robot_id in enumerate(robot_ids):\n            team_id = i // team_size\n            if team_id not in teams:\n                teams[team_id] = []\n            teams[team_id].append(robot_id)\n\n        return teams\n\n    def _calculate_robot_bid(self, robot_state: RobotState, task: Task) -> float:\n        """Calculate bid value for a robot-task combination"""\n        # Calculate cost based on distance, battery, current load\n        distance_cost = np.linalg.norm(robot_state.position - task.target_position)\n        battery_factor = robot_state.battery_level\n        load_factor = 1.0 / (1.0 + len(self._get_robot_tasks(robot_state.robot_id)))\n\n        # Higher bid value means robot wants the task more\n        bid_value = (battery_factor * load_factor) / (distance_cost + 1)\n        return bid_value\n\n    def _get_robot_tasks(self, robot_id: int) -> List[str]:\n        """Get list of tasks assigned to a specific robot"""\n        assigned_tasks = []\n        for task_id, robot_list in self.robot_assignments.items():\n            if robot_id in robot_list:\n                assigned_tasks.append(task_id)\n        return assigned_tasks\n\n    def _get_timestamp(self) -> float:\n        """Get current timestamp"""\n        import time\n        return time.time()\n\nclass CentralizedController:\n    """Centralized controller for multi-robot coordination"""\n\n    def __init__(self, comm_network: CommunicationNetwork):\n        self.comm_network = comm_network\n\n    def compute_optimal_assignment(self, task: Task, robot_ids: List[int]) -> Dict[int, dict]:\n        """Compute optimal task assignment using optimization"""\n        # This is a simplified version - in practice, this would use\n        # more sophisticated optimization algorithms like Hungarian algorithm,\n        # linear programming, or auction algorithms\n\n        assignment = {}\n\n        if task.required_robots <= len(robot_ids):\n            # Assign closest robots to minimize travel time\n            robot_distances = []\n            for robot_id in robot_ids:\n                robot_state = self.comm_network.robot_states[robot_id]\n                distance = np.linalg.norm(\n                    robot_state.position - task.target_position\n                )\n                robot_distances.append((robot_id, distance))\n\n            # Sort by distance and assign closest robots\n            robot_distances.sort(key=lambda x: x[1])\n            assigned_robots = [robot_id for robot_id, _ in robot_distances[:task.required_robots]]\n\n            for robot_id in assigned_robots:\n                assignment[robot_id] = {\n                    \'task_id\': task.task_id,\n                    \'role\': \'primary\' if robot_id == assigned_robots[0] else \'support\',\n                    \'subtask\': self._determine_subtask(robot_id, task, assigned_robots)\n                }\n\n        return assignment\n\n    def _determine_subtask(self, robot_id: int, task: Task, assigned_robots: List[int]) -> str:\n        """Determine specific subtask for a robot in a multi-robot task"""\n        if task.task_type == \'formation\':\n            # Assign formation positions based on robot index\n            robot_idx = assigned_robots.index(robot_id)\n            return f\'formation_position_{robot_idx}\'\n        elif task.task_type == \'navigation\':\n            # Assign navigation roles (leader, follower, scout)\n            if robot_idx == 0:\n                return \'leader\'\n            elif robot_idx == len(assigned_robots) - 1:\n                return \'scout\'\n            else:\n                return \'follower\'\n        else:\n            return \'general\'\n'})}),"\n",(0,i.jsx)(e.h2,{id:"sim-to-real-transfer-framework",children:"Sim-to-Real Transfer Framework"}),"\n",(0,i.jsx)(e.p,{children:"The RL-SAR framework provides a practical approach to sim-to-real transfer:"}),"\n",(0,i.jsx)(e.h3,{id:"policy-deployment-system",children:"Policy Deployment System"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// rl_sar_integration.cpp - C++ integration for sim-to-real transfer\n#include <vector>\n#include <memory>\n#include <string>\n#include <yaml-cpp/yaml.h>\n#include <torch/torch.h>\n#include <onnxruntime_cxx_api.h>\n\n// Model factory for different inference backends\nclass ModelFactory {\npublic:\n    enum ModelType {\n        TORCH,\n        ONNX,\n        TENSORRT\n    };\n\n    static std::unique_ptr<InferenceModel> create_model(ModelType type) {\n        switch(type) {\n            case TORCH:\n                return std::make_unique<TorchModel>();\n            case ONNX:\n                return std::make_unique<ONNXModel>();\n            case TENSORRT:\n                return std::make_unique<TensorRTModel>();\n            default:\n                return std::make_unique<TorchModel>();\n        }\n    }\n};\n\nclass InferenceModel {\npublic:\n    virtual bool load(const std::string& model_path) = 0;\n    virtual std::vector<float> forward(const std::vector<std::vector<float>>& observations) = 0;\n    virtual ~InferenceModel() = default;\n};\n\nclass TorchModel : public InferenceModel {\nprivate:\n    torch::jit::script::Module module;\n    bool loaded = false;\n\npublic:\n    bool load(const std::string& model_path) override {\n        try {\n            module = torch::jit::load(model_path);\n            loaded = true;\n            return true;\n        } catch (const c10::Error& e) {\n            std::cerr << "Error loading Torch model: " << e.msg() << std::endl;\n            loaded = false;\n            return false;\n        }\n    }\n\n    std::vector<float> forward(const std::vector<std::vector<float>>& observations) override {\n        if (!loaded) return {};\n\n        // Convert observations to tensor\n        std::vector<torch::jit::IValue> inputs;\n        for (const auto& obs : observations) {\n            auto tensor = torch::from_blob(\n                const_cast<float*>(obs.data()),\n                {1, static_cast<long>(obs.size())},\n                torch::kFloat\n            ).clone();\n            inputs.push_back(tensor);\n        }\n\n        // Run inference\n        at::Tensor output = module.forward(inputs).toTensor();\n        auto output_acc = output.accessor<float, 2>();\n\n        std::vector<float> result;\n        for (int i = 0; i < output_acc.size(1); ++i) {\n            result.push_back(output_acc[0][i]);\n        }\n\n        return result;\n    }\n};\n\nclass ONNXModel : public InferenceModel {\nprivate:\n    Ort::Env env{ORT_LOGGING_LEVEL_WARNING, "ONNXModel"};\n    Ort::Session *session = nullptr;\n    Ort::AllocatorWithDefaultOptions allocator;\n    bool loaded = false;\n\npublic:\n    bool load(const std::string& model_path) override {\n        try {\n            Ort::SessionOptions session_options;\n            session_options.SetIntraOpNumThreads(1);\n            session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_EXTENDED);\n\n            session = new Ort::Session(env, model_path.c_str(), session_options);\n            loaded = true;\n            return true;\n        } catch (const std::exception& e) {\n            std::cerr << "Error loading ONNX model: " << e.what() << std::endl;\n            loaded = false;\n            return false;\n        }\n    }\n\n    std::vector<float> forward(const std::vector<std::vector<float>>& observations) override {\n        if (!loaded || !session) return {};\n\n        // Prepare input tensor\n        std::vector<int64_t> input_shape{1, static_cast<int64_t>(observations[0].size())};\n        auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\n        auto input_tensor = Ort::Value::CreateTensor<float>(\n            memory_info,\n            const_cast<float*>(observations[0].data()),\n            observations[0].size(),\n            input_shape.data(),\n            input_shape.size()\n        );\n\n        // Run inference\n        char* input_names[] = {"input"};\n        char* output_names[] = {"output"};\n\n        auto output_tensors = session->Run(\n            Ort::RunOptions{nullptr},\n            input_names,\n            &input_tensor,\n            1,\n            output_names,\n            1\n        );\n\n        // Extract output\n        float* floatarr = output_tensors[0].GetTensorMutableData<float>();\n        auto type_info = output_tensors[0].GetTensorTypeAndShapeInfo();\n        std::vector<int64_t> output_shape = type_info.GetShape();\n\n        std::vector<float> result;\n        int output_size = 1;\n        for (auto dim : output_shape) {\n            output_size *= dim;\n        }\n\n        for (int i = 0; i < output_size; ++i) {\n            result.push_back(floatarr[i]);\n        }\n\n        return result;\n    }\n};\n\n// Observation buffer for maintaining temporal history\nclass ObservationBuffer {\nprivate:\n    int num_envs;\n    std::vector<int> obs_dims;\n    int history_length;\n    std::string concat_order;  // "time" or "channel"\n    std::vector<std::vector<std::vector<float>>> buffer;  // [env][time][obs_dim]\n    std::vector<int> current_indices;\n\npublic:\n    ObservationBuffer(int n_envs, const std::vector<int>& dims, int hist_len, const std::string& order = "time")\n        : num_envs(n_envs), obs_dims(dims), history_length(hist_len), concat_order(order) {\n\n        buffer.resize(num_envs);\n        current_indices.resize(num_envs, 0);\n\n        for (int i = 0; i < num_envs; ++i) {\n            buffer[i].resize(history_length);\n            int total_dims = 0;\n            for (int dim : obs_dims) {\n                total_dims += dim;\n            }\n            for (int j = 0; j < history_length; ++j) {\n                buffer[i][j].resize(total_dims, 0.0f);\n            }\n        }\n    }\n\n    void reset(const std::vector<int>& env_ids, const std::vector<float>& init_obs) {\n        for (int env_id : env_ids) {\n            for (int t = 0; t < history_length; ++t) {\n                buffer[env_id][t] = init_obs;\n            }\n            current_indices[env_id] = 0;\n        }\n    }\n\n    void insert(const std::vector<float>& obs) {\n        for (int env = 0; env < num_envs; ++env) {\n            buffer[env][current_indices[env]] = obs;\n            current_indices[env] = (current_indices[env] + 1) % history_length;\n        }\n    }\n\n    std::vector<float> get_obs_vec(const std::vector<int>& time_indices) {\n        std::vector<float> result;\n\n        if (concat_order == "time") {\n            // Concatenate along time dimension: [obs_t-2, obs_t-1, obs_t]\n            for (int time_idx : time_indices) {\n                int buffer_idx = (current_indices[0] + time_idx) % history_length;\n                result.insert(result.end(),\n                             buffer[0][buffer_idx].begin(),\n                             buffer[0][buffer_idx].end());\n            }\n        } else {\n            // Concatenate along channel dimension\n            for (int env = 0; env < num_envs; ++env) {\n                for (int time_idx : time_indices) {\n                    int buffer_idx = (current_indices[env] + time_idx) % history_length;\n                    result.insert(result.end(),\n                                 buffer[env][buffer_idx].begin(),\n                                 buffer[env][buffer_idx].end());\n                }\n            }\n        }\n\n        return result;\n    }\n};\n\n// Real robot interface for Unitree robots\nclass RealRobotInterface {\nprotected:\n    std::string network_interface;\n    bool initialized = false;\n\npublic:\n    RealRobotInterface(const std::string& net_interface) : network_interface(net_interface) {}\n\n    virtual bool initialize() = 0;\n    virtual bool send_command(const std::vector<float>& actions) = 0;\n    virtual std::vector<float> get_sensor_data() = 0;\n    virtual bool shutdown() = 0;\n};\n\n// Example implementation for Unitree Go2 robot\nclass Go2RobotInterface : public RealRobotInterface {\nprivate:\n    void* sdk_handle = nullptr;  // Unitree SDK handle\n    std::vector<float> last_action;\n\npublic:\n    Go2RobotInterface(const std::string& net_interface) : RealRobotInterface(net_interface) {}\n\n    bool initialize() override {\n        // Initialize Unitree SDK\n        // This would involve setting up network connection, calibration, etc.\n        // For this example, we\'ll simulate the initialization\n\n        std::cout << "Initializing Unitree Go2 robot on interface: " << network_interface << std::endl;\n\n        // Initialize SDK\n        // unitree_sdk2::init();\n\n        initialized = true;\n        return initialized;\n    }\n\n    bool send_command(const std::vector<float>& actions) override {\n        if (!initialized) return false;\n\n        // Send actions to robot motors\n        // In real implementation, this would convert actions to motor commands\n        // and send them via the Unitree SDK\n\n        last_action = actions;\n\n        // Example: Convert actions to joint positions/torques\n        // for (size_t i = 0; i < actions.size() && i < joint_commands.size(); ++i) {\n        //     joint_commands[i].position = actions[i];\n        //     joint_commands[i].kp = 0.0;  // Use learned gains if available\n        //     joint_commands[i].kd = 0.0;\n        // }\n\n        // Send commands via SDK\n        // unitree_sdk2::send_joint_commands(joint_commands);\n\n        return true;\n    }\n\n    std::vector<float> get_sensor_data() override {\n        if (!initialized) return {};\n\n        // Get sensor data from robot\n        // In real implementation, this would read from IMU, encoders, etc.\n\n        std::vector<float> sensor_data(45);  // Example: 45-dim observation space\n\n        // Simulate getting sensor data\n        // This would typically include:\n        // - Joint positions (12 values for Go2)\n        // - Joint velocities (12 values)\n        // - IMU data (6 values: angular velocity + linear acceleration)\n        // - Gravity vector (3 values)\n        // - Command history (previous actions)\n\n        // Fill with simulated data\n        for (size_t i = 0; i < sensor_data.size(); ++i) {\n            sensor_data[i] = static_cast<float>(rand()) / RAND_MAX * 2.0f - 1.0f;  // Random values in [-1, 1]\n        }\n\n        return sensor_data;\n    }\n\n    bool shutdown() override {\n        if (!initialized) return true;\n\n        // Stop robot motors and clean up\n        // Send zero commands to all joints\n        std::vector<float> zero_commands(12, 0.0f);\n        send_command(zero_commands);\n\n        // unitree_sdk2::cleanup();\n        initialized = false;\n\n        return true;\n    }\n};\n\n// Main control loop for sim-to-real transfer\nclass Sim2RealController {\nprivate:\n    std::unique_ptr<InferenceModel> policy_model;\n    std::unique_ptr<ObservationBuffer> obs_buffer;\n    std::unique_ptr<RealRobotInterface> robot_interface;\n    std::unique_ptr<DomainRandomizer> domain_randomizer;\n\npublic:\n    Sim2RealController(const std::string& model_path, const std::string& robot_type,\n                      const std::string& network_interface) {\n\n        // Initialize policy model\n        policy_model = ModelFactory::create_model(ModelFactory::ONNX);\n        policy_model->load(model_path);\n\n        // Initialize observation buffer (example parameters)\n        std::vector<int> obs_dims = {3, 3, 3, 12, 12, 12};  // commands, ang_vel, gravity, pos, vel, actions\n        obs_buffer = std::make_unique<ObservationBuffer>(1, obs_dims, 6, "time");\n\n        // Initialize robot interface\n        if (robot_type == "go2") {\n            robot_interface = std::make_unique<Go2RobotInterface>(network_interface);\n        }\n        // Add other robot types as needed\n\n        // Initialize domain randomizer for robustness\n        domain_randomizer = std::make_unique<DomainRandomizer>();\n    }\n\n    bool run_control_loop() {\n        if (!robot_interface->initialize()) {\n            std::cerr << "Failed to initialize robot interface" << std::endl;\n            return false;\n        }\n\n        std::cout << "Starting control loop..." << std::endl;\n\n        for (int step = 0; step < 100000; ++step) {  // Run for 100k steps or until stopped\n            // Get sensor data from robot\n            auto sensor_data = robot_interface->get_sensor_data();\n            if (sensor_data.empty()) {\n                std::cerr << "Failed to get sensor data, stopping control loop" << std::endl;\n                break;\n            }\n\n            // Insert observation into buffer\n            obs_buffer->insert(sensor_data);\n\n            // Get historical observations for policy input\n            std::vector<int> history_indices = {0, 1, 2, 3, 4, 5};  // Last 6 timesteps\n            auto policy_input = obs_buffer->get_obs_vec(history_indices);\n\n            // Run policy inference\n            auto actions = policy_model->forward({policy_input});\n\n            // Apply domain randomization to actions for robustness\n            auto randomized_actions = apply_action_randomization(actions);\n\n            // Send commands to robot\n            if (!robot_interface->send_command(randomized_actions)) {\n                std::cerr << "Failed to send commands to robot, stopping control loop" << std::endl;\n                break;\n            }\n\n            // Small delay to control loop frequency\n            std::this_thread::sleep_for(std::chrono::milliseconds(10));  // 100Hz control\n        }\n\n        robot_interface->shutdown();\n        return true;\n    }\n\nprivate:\n    std::vector<float> apply_action_randomization(const std::vector<float>& actions) {\n        // Apply small randomization to actions for robustness\n        std::vector<float> randomized_actions = actions;\n\n        for (auto& action : randomized_actions) {\n            // Add small noise (\xb12% of action range)\n            float noise = (static_cast<float>(rand()) / RAND_MAX - 0.5f) * 0.04f;\n            action += noise;\n\n            // Clamp to valid range [-1, 1]\n            action = std::max(-1.0f, std::min(1.0f, action));\n        }\n\n        return randomized_actions;\n    }\n};\n'})}),"\n",(0,i.jsx)(e.h3,{id:"python-interface-for-sim-to-real-transfer",children:"Python Interface for Sim-to-Real Transfer"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# sim2real_interface.py - Python interface for sim-to-real transfer\nimport subprocess\nimport sys\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport yaml\nimport onnxruntime as ort\nimport torch\nimport time\n\nclass PolicyConverter:\n    """Convert policies between different formats for deployment"""\n\n    @staticmethod\n    def torch_to_onnx(torch_model_path: str, onnx_model_path: str, input_shape: tuple):\n        """Convert PyTorch model to ONNX format"""\n        try:\n            # Load PyTorch model\n            model = torch.jit.load(torch_model_path)\n            model.eval()\n\n            # Create dummy input\n            dummy_input = torch.randn(input_shape)\n\n            # Export to ONNX\n            torch.onnx.export(\n                model,\n                dummy_input,\n                onnx_model_path,\n                export_params=True,\n                opset_version=11,\n                do_constant_folding=True,\n                input_names=[\'input\'],\n                output_names=[\'output\'],\n                dynamic_axes={\n                    \'input\': {0: \'batch_size\'},\n                    \'output\': {0: \'batch_size\'}\n                }\n            )\n\n            print(f"Successfully converted {torch_model_path} to {onnx_model_path}")\n\n            # Verify conversion\n            PolicyConverter.verify_conversion(torch_model_path, onnx_model_path, input_shape)\n\n            return True\n        except Exception as e:\n            print(f"Error converting model: {e}")\n            return False\n\n    @staticmethod\n    def onnx_to_torch(onnx_model_path: str, torch_model_path: str):\n        """Convert ONNX model back to PyTorch using onnx2torch"""\n        try:\n            import onnx2torch\n            import onnx\n\n            # Load ONNX model\n            onnx_model = onnx.load(onnx_model_path)\n\n            # Convert to PyTorch\n            torch_model = onnx2torch.convert(onnx_model)\n\n            # Save as TorchScript\n            torch.jit.save(torch.jit.script(torch_model), torch_model_path)\n\n            print(f"Successfully converted {onnx_model_path} to {torch_model_path}")\n\n            # Verify conversion\n            PolicyConverter.verify_onnx_torch_conversion(onnx_model_path, torch_model_path)\n\n            return True\n        except ImportError:\n            print("onnx2torch not installed. Install with: pip install onnx2torch")\n            return False\n        except Exception as e:\n            print(f"Error converting ONNX to PyTorch: {e}")\n            return False\n\n    @staticmethod\n    def verify_conversion(torch_model_path: str, onnx_model_path: str, input_shape: tuple):\n        """Verify that PyTorch and ONNX models produce similar outputs"""\n        # Load models\n        torch_model = torch.jit.load(torch_model_path)\n        torch_model.eval()\n\n        ort_session = ort.InferenceSession(onnx_model_path)\n\n        # Create test input\n        test_input = torch.randn(input_shape)\n        numpy_input = test_input.detach().cpu().numpy()\n\n        # Run inference\n        with torch.no_grad():\n            torch_output = torch_model(test_input).detach().cpu().numpy()\n\n        onnx_output = ort_session.run(None, {\'input\': numpy_input})[0]\n\n        # Compare outputs\n        max_diff = np.max(np.abs(torch_output - onnx_output))\n\n        if max_diff < 1e-5:\n            print(f"\u2713 Conversion verified successfully. Max difference: {max_diff:.2e}")\n        else:\n            print(f"\u2717 Conversion verification failed. Max difference: {max_diff:.2e}")\n\n    @staticmethod\n    def verify_onnx_torch_conversion(onnx_model_path: str, torch_model_path: str):\n        """Verify ONNX to PyTorch conversion"""\n        # Load models\n        torch_model = torch.jit.load(torch_model_path)\n        torch_model.eval()\n\n        ort_session = ort.InferenceSession(onnx_model_path)\n\n        # Create test input\n        input_shape = (1, 45)  # Example: 45-dim input for humanoid\n        test_input = torch.randn(input_shape)\n        numpy_input = test_input.detach().cpu().numpy()\n\n        # Run inference\n        with torch.no_grad():\n            torch_output = torch_model(test_input).detach().cpu().numpy()\n\n        onnx_output = ort_session.run(None, {\'input\': numpy_input})[0]\n\n        # Compare outputs\n        max_diff = np.max(np.abs(torch_output - onnx_output))\n\n        if max_diff < 1e-4:\n            print(f"\u2713 ONNX->PyTorch conversion verified. Max difference: {max_diff:.2e}")\n        else:\n            print(f"\u2717 ONNX->PyTorch conversion failed. Max difference: {max_diff:.2e}")\n\nclass RealRobotController:\n    """Controller for deploying policies to real robots"""\n\n    def __init__(self, robot_type: str, network_interface: str, policy_path: str):\n        self.robot_type = robot_type\n        self.network_interface = network_interface\n        self.policy_path = policy_path\n        self.ros_workspace = Path.home() / "rl_sar"  # Default RL-SAR workspace\n\n    def deploy_policy(self):\n        """Deploy policy to real robot"""\n        print(f"Deploying policy to {self.robot_type} robot...")\n\n        # Check if ROS workspace exists\n        if not self.ros_workspace.exists():\n            print(f"ROS workspace not found at {self.ros_workspace}")\n            return False\n\n        # Verify policy file exists\n        policy_file = Path(self.policy_path)\n        if not policy_file.exists():\n            print(f"Policy file not found: {self.policy_path}")\n            return False\n\n        # Determine executable based on robot type\n        if self.robot_type.lower() == "a1":\n            executable = "rl_real_a1"\n        elif self.robot_type.lower() == "go2":\n            executable = "rl_real_go2"\n        elif self.robot_type.lower() == "g1":\n            executable = "rl_real_g1"\n        else:\n            print(f"Unsupported robot type: {self.robot_type}")\n            return False\n\n        # Check if policy is in ONNX format (preferred for deployment)\n        if policy_file.suffix.lower() == \'.pt\':\n            print("Converting PyTorch policy to ONNX for deployment...")\n            onnx_path = policy_file.with_suffix(\'.onnx\')\n            if PolicyConverter.torch_to_onnx(str(policy_file), str(onnx_path), (1, 45)):\n                self.policy_path = str(onnx_path)\n            else:\n                print("Failed to convert policy to ONNX, continuing with PyTorch...")\n\n        # Prepare deployment command\n        if self.robot_type.lower() == "g1":\n            # G1 requires network interface\n            command = [\n                "ros2", "run", "rl_sar", executable,\n                self.network_interface\n            ]\n        elif self.robot_type.lower() == "go2":\n            # Go2 can have optional \'wheel\' argument\n            command = [\n                "ros2", "run", "rl_sar", executable,\n                self.network_interface\n            ]\n        else:\n            # A1 and other robots\n            command = [\n                "ros2", "run", "rl_sar", executable\n            ]\n\n        print(f"Executing command: {\' \'.join(command)}")\n\n        try:\n            # Change to workspace directory\n            original_cwd = os.getcwd()\n            os.chdir(self.ros_workspace)\n\n            # Source ROS environment\n            # In practice, you\'d want to source the workspace setup file\n            # This is just a simulation of the process\n            print(f"Changed to workspace: {self.ros_workspace}")\n            print(f"Deployment command prepared: {\' \'.join(command)}")\n            print("In a real deployment, this would execute the robot control program.")\n\n            # For simulation purposes, just return success\n            return True\n\n        except Exception as e:\n            print(f"Error during deployment: {e}")\n            return False\n        finally:\n            os.chdir(original_cwd)\n\n    def setup_onboard_deployment(self):\n        """Setup for onboard deployment on robot\'s Jetson computer"""\n        print("Setting up onboard deployment on robot\'s Jetson computer...")\n\n        setup_steps = [\n            "SSH into robot\'s onboard computer",\n            "Clone RL-SAR repository",\n            "Build with CMake",\n            "Configure systemd service for auto-start",\n            "Test deployment"\n        ]\n\n        for i, step in enumerate(setup_steps, 1):\n            print(f"{i}. {step}")\n\n        # Example commands for Jetson deployment\n        jetson_commands = [\n            "ssh unitree@192.168.123.18  # Password: 123",\n            "git clone --recursive --depth 1 https://github.com/fan-ziqi/rl_sar.git",\n            "cd rl_sar && ./build.sh -m",\n            "./cmake_build/bin/rl_real_go2 eth0",\n            "Setup systemd service for auto-start"\n        ]\n\n        print("\\nExample commands for Jetson deployment:")\n        for cmd in jetson_commands:\n            print(f"  $ {cmd}")\n\n        return True\n\ndef main():\n    """Main function for sim-to-real deployment"""\n    print("RL-SAR: Reinforcement Learning Simulation to Real Deployment Tool")\n    print("=" * 60)\n\n    # Example usage\n    controller = RealRobotController(\n        robot_type="go2",\n        network_interface="eth0",\n        policy_path="policy/go2/himloco/himloco.onnx"\n    )\n\n    # Deploy policy\n    success = controller.deploy_policy()\n\n    if success:\n        print("\\n\u2713 Policy deployment completed successfully!")\n        print("The robot should now be executing the learned policy.")\n    else:\n        print("\\n\u2717 Policy deployment failed!")\n        print("Check the error messages above and try again.")\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"Advanced simulation techniques for humanoid robotics encompass domain randomization, multi-robot coordination, and sim-to-real transfer methodologies that bridge the gap between virtual and physical environments. These techniques enable robust policy learning, distributed control of multiple robots, and deployment of simulation-trained behaviors to real hardware platforms."}),"\n",(0,i.jsx)(e.p,{children:"Key capabilities include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Domain Randomization"}),": Systematic parameter variation during training to improve policy robustness"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-Robot Coordination"}),": Frameworks for distributed control using centralized, decentralized, hierarchical, or market-based strategies"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sim-to-Real Transfer"}),": Deployment of reinforcement learning policies from simulation to hardware using frameworks like RL-SAR"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"In Chapter 9, we will transition to Module 3: Edge Computing and Embedded Systems, beginning with real-time control systems and embedded hardware architectures for humanoid robotics applications."}),"\n",(0,i.jsx)(e.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Conceptual"}),': Explain how domain randomization addresses the "reality gap" in sim-to-real transfer. What are the trade-offs between randomization range and policy performance?']}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Applied"}),": Implement a decentralized coordination algorithm for 3 humanoid robots performing a formation task, including communication protocols and collision avoidance."]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Structural"}),": Compare the computational requirements and latency constraints for deploying reinforcement learning policies on embedded systems versus cloud-based systems for humanoid control."]}),"\n"]}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}},8453(n,e,t){t.d(e,{R:()=>a,x:()=>s});var o=t(6540);const i={},r=o.createContext(i);function a(n){const e=o.useContext(r);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);